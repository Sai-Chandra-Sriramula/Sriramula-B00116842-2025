{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Add, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "with open(\"E:/ICS/word_mappings.pkl\", \"rb\") as f:\n",
    "    word_mappings = pickle.load(f)\n",
    "    word2idx = word_mappings['word2idx']\n",
    "    idx2word = word_mappings['idx2word']\n",
    "    max_length = word_mappings['max_length']\n",
    "\n",
    "with open(\"E:/ICS/features/train_features.pkl\", \"rb\") as f:\n",
    "    train_features = pickle.load(f)\n",
    "\n",
    "with open(\"E:/ICS/features/val_features.pkl\", \"rb\") as f:\n",
    "    val_features = pickle.load(f)\n",
    "\n",
    "with open(\"E:/ICS/cleaned_captions.pkl\", \"rb\") as f:\n",
    "    cleaned_captions = pickle.load(f)\n",
    "\n",
    "# Utility: Convert words to sequence\n",
    "def caption_to_seq(caption):\n",
    "    return [word2idx.get(w, word2idx['<unk>']) for w in caption.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and validation data\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "for img, features in train_features.items():\n",
    "    for cap in cleaned_captions.get(img, []):\n",
    "        seq = caption_to_seq(cap)\n",
    "        train_data.append((features, seq))\n",
    "\n",
    "for img, features in val_features.items():\n",
    "    for cap in cleaned_captions.get(img, []):\n",
    "        seq = caption_to_seq(cap)\n",
    "        val_data.append((features, seq))\n",
    "\n",
    "# Pad sequences\n",
    "def create_dataset(data, batch_size):\n",
    "    img_feats = []\n",
    "    cap_seqs = []\n",
    "    for feature, seq in data:\n",
    "        img_feats.append(feature)\n",
    "        cap_seqs.append(seq)\n",
    "    cap_seqs = pad_sequences(cap_seqs, maxlen=max_length, padding='post')\n",
    "    return tf.data.Dataset.from_tensor_slices((np.array(img_feats), cap_seqs)).shuffle(1000).batch(batch_size)\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = create_dataset(train_data, batch_size)\n",
    "val_dataset = create_dataset(val_data, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Encoder\n",
    "def build_encoder(embedding_dim):\n",
    "    inputs = Input(shape=(2048,), name='image_input')\n",
    "    fc = Dense(embedding_dim, activation='relu', name='encoder_fc')(inputs)\n",
    "    return Model(inputs, fc, name='CNN_Encoder')\n",
    "\n",
    "# Define the Decoder with Attention\n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        context = attention_weights * features\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, attention_weights\n",
    "\n",
    "class RNN_Decoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, units, vocab_size):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "        self.fc1 = Dense(units)\n",
    "        self.fc2 = Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(units)\n",
    "\n",
    "    def call(self, x, features, hidden):\n",
    "        context_vector, _ = self.attention(tf.expand_dims(features, 1), hidden)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state_h, _ = self.lstm(x)\n",
    "        x = self.fc1(output)\n",
    "        x = self.fc2(x)\n",
    "        return x, state_h\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "embedding_dim = 256\n",
    "units = 512\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "encoder = build_encoder(embedding_dim)\n",
    "decoder = RNN_Decoder(embedding_dim, units, vocab_size)\n",
    "\n",
    "optimizer = Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    return tf.reduce_mean(loss * mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Step\n",
    "def train_step(img_tensor, target):\n",
    "    loss = 0\n",
    "    hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        features = encoder(img_tensor)\n",
    "        for i in range(1, target.shape[1]):\n",
    "            dec_input = tf.expand_dims(target[:, i - 1], 1)\n",
    "            predictions, hidden = decoder(dec_input, features, hidden)\n",
    "            loss += loss_function(target[:, i], predictions[:, 0, :])\n",
    "            train_accuracy.update_state(target[:, i], predictions[:, 0, :])\n",
    "\n",
    "    total_loss = loss / int(target.shape[1])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████| 455/455 [1:20:50<00:00, 10.66s/it, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3718, Accuracy: 0.0779, Val Loss: 1.2121, Val Accuracy: 0.0989, Time: 4994.78s\n",
      " Best model saved!\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████| 455/455 [1:21:39<00:00, 10.77s/it, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.0923, Accuracy: 0.1046, Val Loss: 1.1248, Val Accuracy: 0.1048, Time: 5045.57s\n",
      " Best model saved!\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████| 455/455 [1:19:28<00:00, 10.48s/it, loss=1.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.0013, Accuracy: 0.1110, Val Loss: 1.1000, Val Accuracy: 0.1066, Time: 4912.32s\n",
      " Best model saved!\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████| 455/455 [1:20:41<00:00, 10.64s/it, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.9446, Accuracy: 0.1151, Val Loss: 1.1008, Val Accuracy: 0.1059, Time: 4985.17s\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████| 455/455 [1:20:03<00:00, 10.56s/it, loss=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.8997, Accuracy: 0.1188, Val Loss: 1.1064, Val Accuracy: 0.1073, Time: 4946.77s\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████| 455/455 [1:21:38<00:00, 10.77s/it, loss=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.8614, Accuracy: 0.1223, Val Loss: 1.1154, Val Accuracy: 0.1068, Time: 5042.15s\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████| 455/455 [1:18:39<00:00, 10.37s/it, loss=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.8254, Accuracy: 0.1258, Val Loss: 1.1283, Val Accuracy: 0.1067, Time: 4859.65s\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████| 455/455 [1:23:29<00:00, 11.01s/it, loss=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.7919, Accuracy: 0.1294, Val Loss: 1.1408, Val Accuracy: 0.1055, Time: 5149.90s\n",
      "\n",
      "Early stopping triggered.\n",
      "\n",
      " Training complete. Final model saved.\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    train_loop = tqdm(train_dataset, desc=\"Training\", ncols=100)\n",
    "    for (batch, (img_tensor, target)) in enumerate(train_loop):\n",
    "        batch_loss = train_step(img_tensor, target)\n",
    "        total_loss += batch_loss\n",
    "        train_loop.set_postfix(loss=batch_loss.numpy())\n",
    "\n",
    "    for img_tensor, target in val_dataset:\n",
    "        hidden = decoder.reset_state(batch_size=target.shape[0])\n",
    "        features = encoder(img_tensor)\n",
    "        loss = 0\n",
    "        for i in range(1, target.shape[1]):\n",
    "            dec_input = tf.expand_dims(target[:, i - 1], 1)\n",
    "            predictions, hidden = decoder(dec_input, features, hidden)\n",
    "            loss += loss_function(target[:, i], predictions[:, 0, :])\n",
    "            val_accuracy.update_state(target[:, i], predictions[:, 0, :])\n",
    "        total_val_loss += loss / int(target.shape[1])\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataset)\n",
    "    avg_val_loss = total_val_loss / len(val_dataset)\n",
    "    train_acc = train_accuracy.result()\n",
    "    val_acc = val_accuracy.result()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_train_loss:.4f}, Accuracy: {train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_acc:.4f}, Time: {time.time()-start:.2f}s\")\n",
    "\n",
    "    train_accuracy.reset_state()\n",
    "    val_accuracy.reset_state()\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        wait = 0\n",
    "        encoder.save(\"E:/ICS/saved_models/encoder_best.keras\")\n",
    "        decoder.save(\"E:/ICS/saved_models/decoder_best.keras\")\n",
    "        print(\" Best model saved!\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"\\nEarly stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"\\n Training complete. Final model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
