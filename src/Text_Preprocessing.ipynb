{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1000268201_693b08cb0e.jpg\n",
      "- <start> a child in a pink dress is climbing up a set of stairs in an entry way <end>\n",
      "- <start> a girl going into a wooden building <end>\n",
      "- <start> a little girl climbing into a wooden playhouse <end>\n",
      "- <start> a little girl climbing the stairs to her playhouse <end>\n",
      "- <start> a little girl in a pink dress going into a wooden cabin <end>\n",
      "\n",
      "\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "- <start> a black dog and a spotted dog are fighting <end>\n",
      "- <start> a black dog and a tricolored dog playing with each other on the road <end>\n",
      "- <start> a black dog and a white dog with brown spots are staring at each other in the street <end>\n",
      "- <start> two dogs of different breeds looking at each other on the road <end>\n",
      "- <start> two dogs on pavement moving toward each other <end>\n",
      "\n",
      "\n",
      "Image: 1002674143_1b742ab4b8.jpg\n",
      "- <start> a little girl covered in paint sits in front of a painted rainbow with her hands in a bowl <end>\n",
      "- <start> a little girl is sitting in front of a large painted rainbow <end>\n",
      "- <start> a small girl in the grass plays with fingerpaints in front of a white canvas with a rainbow on it <end>\n",
      "- <start> there is a girl with pigtails sitting in front of a rainbow painting <end>\n",
      "- <start> young girl with pigtails painting outside in the grass <end>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Function to clean captions\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
    "    text = text.strip()  # Remove leading/trailing spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to all captions\n",
    "cleaned_captions_dict = {}\n",
    "\n",
    "with open(\"captions.pkl\", \"rb\") as f:\n",
    "    captions_dict = pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "for img, captions in captions_dict.items():\n",
    "    cleaned_captions_dict[img] = [\"<start> \" + clean_text(cap) + \" <end>\" for cap in captions]\n",
    "\n",
    "# Print example\n",
    "for img, caps in list(cleaned_captions_dict.items())[:3]:\n",
    "    print(f\"Image: {img}\")\n",
    "    for cap in caps:\n",
    "        print(f\"- {cap}\")\n",
    "    print(\"\\n\")  # Add spacing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 5202\n",
      "Sample word2idx mappings: [('<pad>', 0), ('<unk>', 1), ('<start>', 2), ('a', 3), ('child', 4), ('in', 5), ('pink', 6), ('dress', 7), ('is', 8), ('climbing', 9)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Collect all words from captions\n",
    "all_words = []\n",
    "for captions in cleaned_captions_dict.values():\n",
    "    for caption in captions:\n",
    "        all_words.extend(caption.split())\n",
    "\n",
    "# Count word frequencies\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Create a vocabulary (word2idx and idx2word)\n",
    "vocab = [word for word, count in word_counts.items() if count >= 2]  # Keep words appearing at least twice\n",
    "vocab.insert(0, \"<pad>\")  # Padding token\n",
    "vocab.insert(1, \"<unk>\")  # Unknown token\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# Print vocabulary size and sample mappings\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(\"Sample word2idx mappings:\", list(word2idx.items())[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Captions to Sequences\n",
    "**Tokenaization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1000268201_693b08cb0e.jpg\n",
      "[2, 3, 4, 5, 3, 6, 7, 8, 9, 10, 3, 11, 12, 13, 5, 14, 1, 15, 16]\n",
      "[2, 3, 17, 18, 19, 3, 20, 21, 16]\n",
      "[2, 3, 22, 17, 9, 19, 3, 20, 23, 16]\n",
      "[2, 3, 22, 17, 9, 24, 13, 25, 26, 23, 16]\n",
      "[2, 3, 22, 17, 5, 3, 6, 7, 18, 19, 3, 20, 27, 16]\n",
      "\n",
      "\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "[2, 3, 28, 29, 30, 3, 31, 29, 32, 33, 16]\n",
      "[2, 3, 28, 29, 30, 3, 34, 29, 35, 36, 37, 38, 39, 24, 40, 16]\n",
      "[2, 3, 28, 29, 30, 3, 41, 29, 36, 42, 43, 32, 44, 45, 37, 38, 5, 24, 46, 16]\n",
      "[2, 47, 48, 12, 49, 50, 51, 45, 37, 38, 39, 24, 40, 16]\n",
      "[2, 47, 48, 39, 52, 53, 54, 37, 38, 16]\n",
      "\n",
      "\n",
      "Image: 1002674143_1b742ab4b8.jpg\n",
      "[2, 3, 22, 17, 55, 5, 56, 57, 5, 58, 12, 3, 59, 60, 36, 26, 61, 5, 3, 62, 16]\n",
      "[2, 3, 22, 17, 8, 63, 5, 58, 12, 3, 64, 59, 60, 16]\n",
      "[2, 3, 65, 17, 5, 24, 66, 67, 36, 68, 5, 58, 12, 3, 41, 69, 36, 3, 60, 39, 70, 16]\n",
      "[2, 71, 8, 3, 17, 36, 72, 63, 5, 58, 12, 3, 60, 73, 16]\n",
      "[2, 74, 17, 36, 72, 73, 75, 5, 24, 66, 16]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert captions into sequences of word indices\n",
    "captions_sequences = {}\n",
    "\n",
    "for img, captions in cleaned_captions_dict.items():\n",
    "    sequences = []\n",
    "    for caption in captions:\n",
    "        seq = [word2idx.get(word, word2idx[\"<unk>\"]) for word in caption.split()]  # Convert words to indices\n",
    "        sequences.append(seq)\n",
    "    captions_sequences[img] = sequences\n",
    "\n",
    "# Print some sample sequences\n",
    "for img, seqs in list(captions_sequences.items())[:3]:  # Show first 3 images\n",
    "    print(f\"Image: {img}\")\n",
    "    for seq in seqs:\n",
    "        print(seq)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max caption length: 37\n",
      "Image: 1000268201_693b08cb0e.jpg\n",
      "[ 2  3  4  5  3  6  7  8  9 10  3 11 12 13  5 14  1 15 16  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 17 18 19  3 20 21 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 22 17  9 19  3 20 23 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 22 17  9 24 13 25 26 23 16  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 22 17  5  3  6  7 18 19  3 20 27 16  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Image: 1001773457_577c3a7d70.jpg\n",
      "[ 2  3 28 29 30  3 31 29 32 33 16  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 28 29 30  3 34 29 35 36 37 38 39 24 40 16  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 28 29 30  3 41 29 36 42 43 32 44 45 37 38  5 24 46 16  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2 47 48 12 49 50 51 45 37 38 39 24 40 16  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2 47 48 39 52 53 54 37 38 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n",
      "Image: 1002674143_1b742ab4b8.jpg\n",
      "[ 2  3 22 17 55  5 56 57  5 58 12  3 59 60 36 26 61  5  3 62 16  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 22 17  8 63  5 58 12  3 64 59 60 16  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2  3 65 17  5 24 66 67 36 68  5 58 12  3 41 69 36  3 60 39 70 16  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2 71  8  3 17 36 72 63  5 58 12  3 60 73 16  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 2 74 17 36 72 73 75  5 24 66 16  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Find maximum caption length\n",
    "max_caption_length = max(len(seq) for seqs in captions_sequences.values() for seq in seqs)\n",
    "print(f\"Max caption length: {max_caption_length}\")\n",
    "\n",
    "# Pad sequences\n",
    "padded_sequences = {}\n",
    "for img, seqs in captions_sequences.items():\n",
    "    padded_sequences[img] = pad_sequences(seqs, maxlen=max_caption_length, padding='post')\n",
    "\n",
    "# Print some padded sequences\n",
    "for img, seqs in list(padded_sequences.items())[:3]:  # Show first 3 images\n",
    "    print(f\"Image: {img}\")\n",
    "    for seq in seqs:\n",
    "        print(seq)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
